{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and create the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\source\\repos\\DeepLearningCourse\\sessoes\\sessao4\\redes_neurais_artificiais\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd())\n",
    "print(os.getcwd())\n",
    "\n",
    "#Importing dataset\n",
    "import pandas as pd\n",
    "previsores = pd.read_csv('entradas_breast.csv')\n",
    "classe = pd.read_csv('saidas_breast.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importacao da validacao cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcao de criacao da rede neural com camada de dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetwork():\n",
    "    classificador = Sequential()\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'random_uniform', input_dim = 30))\n",
    "    classificador.add(Dropout(0.2))\n",
    "    classificador.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'random_uniform'))\n",
    "    classificador.add(Dropout(0.2))\n",
    "    classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    #Compile the neural network\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, decay=0.0001, clipvalue=0.5)\n",
    "    classificador.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "    return classificador"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intanciar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = KerasClassifier(model = createNetwork, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 1.7688 - binary_accuracy: 0.5820\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6105 - binary_accuracy: 0.6387\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7381 - binary_accuracy: 0.6289\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5824 - binary_accuracy: 0.6406\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6024 - binary_accuracy: 0.6855\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6005 - binary_accuracy: 0.6934\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5814 - binary_accuracy: 0.6953\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6017 - binary_accuracy: 0.7324\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6429 - binary_accuracy: 0.7129\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5985 - binary_accuracy: 0.7695\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5883 - binary_accuracy: 0.7734\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5716 - binary_accuracy: 0.7656\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5249 - binary_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5458 - binary_accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6331 - binary_accuracy: 0.8145\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5685 - binary_accuracy: 0.8281\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7374 - binary_accuracy: 0.8359\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9163 - binary_accuracy: 0.8066\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7485 - binary_accuracy: 0.8027\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8929 - binary_accuracy: 0.8066\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8179 - binary_accuracy: 0.8223\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7064 - binary_accuracy: 0.7969\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8074 - binary_accuracy: 0.8164\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7996 - binary_accuracy: 0.8281\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6507 - binary_accuracy: 0.8262\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5861 - binary_accuracy: 0.7969\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5679 - binary_accuracy: 0.8223\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9557 - binary_accuracy: 0.8164\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8945 - binary_accuracy: 0.8379\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 981us/step - loss: 0.8991 - binary_accuracy: 0.8379\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3919 - binary_accuracy: 0.8379\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9926 - binary_accuracy: 0.8555\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.7227 - binary_accuracy: 0.8652\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5690 - binary_accuracy: 0.8613\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3622 - binary_accuracy: 0.8184\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6268 - binary_accuracy: 0.8574\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7068 - binary_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7932 - binary_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1163 - binary_accuracy: 0.8301\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7876 - binary_accuracy: 0.8320\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7036 - binary_accuracy: 0.8555\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 977us/step - loss: 1.3878 - binary_accuracy: 0.8301\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9099 - binary_accuracy: 0.8438\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2831 - binary_accuracy: 0.8555\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6810 - binary_accuracy: 0.8613\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.4965 - binary_accuracy: 0.8516\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 981us/step - loss: 0.5085 - binary_accuracy: 0.8438\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 999us/step - loss: 1.0906 - binary_accuracy: 0.8398\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8466 - binary_accuracy: 0.8652\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2036 - binary_accuracy: 0.8496\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6631 - binary_accuracy: 0.8574\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9408 - binary_accuracy: 0.8496\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1077 - binary_accuracy: 0.8301\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5247 - binary_accuracy: 0.8320\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7333 - binary_accuracy: 0.8555\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0391 - binary_accuracy: 0.8320\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9879 - binary_accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0538 - binary_accuracy: 0.8516\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0980 - binary_accuracy: 0.8281\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0156 - binary_accuracy: 0.8555\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1021 - binary_accuracy: 0.8164\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2054 - binary_accuracy: 0.8496\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7831 - binary_accuracy: 0.8438\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5085 - binary_accuracy: 0.8594\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1947 - binary_accuracy: 0.8320\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0273 - binary_accuracy: 0.8418\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6977 - binary_accuracy: 0.8535\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9093 - binary_accuracy: 0.8711\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6864 - binary_accuracy: 0.8477\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0288 - binary_accuracy: 0.8535\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7428 - binary_accuracy: 0.8906\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2879 - binary_accuracy: 0.8398\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4802 - binary_accuracy: 0.8672\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3301 - binary_accuracy: 0.8477\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5498 - binary_accuracy: 0.8359\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6979 - binary_accuracy: 0.8340\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8747 - binary_accuracy: 0.8535\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4402 - binary_accuracy: 0.8301\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0420 - binary_accuracy: 0.8398\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8484 - binary_accuracy: 0.8418\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3122 - binary_accuracy: 0.8613\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1711 - binary_accuracy: 0.8574\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.9827 - binary_accuracy: 0.8320\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3168 - binary_accuracy: 0.8379\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2059 - binary_accuracy: 0.8496\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2968 - binary_accuracy: 0.8281\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6008 - binary_accuracy: 0.8516\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3211 - binary_accuracy: 0.8477\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8917 - binary_accuracy: 0.8535\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7230 - binary_accuracy: 0.8379\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6988 - binary_accuracy: 0.8457\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 962us/step - loss: 0.6843 - binary_accuracy: 0.8555\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0487 - binary_accuracy: 0.8613\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0808 - binary_accuracy: 0.8398\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6936 - binary_accuracy: 0.8340\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8426 - binary_accuracy: 0.8730\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7970 - binary_accuracy: 0.8496\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6856 - binary_accuracy: 0.8574\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5980 - binary_accuracy: 0.8418\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5491 - binary_accuracy: 0.8262\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 1.0839 - binary_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6637 - binary_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5877 - binary_accuracy: 0.7227\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.5897 - binary_accuracy: 0.6914\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6102 - binary_accuracy: 0.7188\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5113 - binary_accuracy: 0.7363\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4883 - binary_accuracy: 0.7715\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5682 - binary_accuracy: 0.7793\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5294 - binary_accuracy: 0.7852\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4822 - binary_accuracy: 0.8145\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5754 - binary_accuracy: 0.7734\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4612 - binary_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 999us/step - loss: 0.5081 - binary_accuracy: 0.7832\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6065 - binary_accuracy: 0.8086\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4712 - binary_accuracy: 0.8125\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9075 - binary_accuracy: 0.8008\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6925 - binary_accuracy: 0.8379\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6504 - binary_accuracy: 0.8008\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7114 - binary_accuracy: 0.8281\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4283 - binary_accuracy: 0.8398\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 975us/step - loss: 0.5681 - binary_accuracy: 0.8203\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9036 - binary_accuracy: 0.8086\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 986us/step - loss: 0.5714 - binary_accuracy: 0.8242\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 986us/step - loss: 0.5241 - binary_accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.7831 - binary_accuracy: 0.8359\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6642 - binary_accuracy: 0.8438\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5482 - binary_accuracy: 0.8184\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6007 - binary_accuracy: 0.8496\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5410 - binary_accuracy: 0.8535\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5503 - binary_accuracy: 0.8359\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5868 - binary_accuracy: 0.8477\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7814 - binary_accuracy: 0.8438\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5669 - binary_accuracy: 0.8652\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 999us/step - loss: 0.4502 - binary_accuracy: 0.8516\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.6865 - binary_accuracy: 0.8496\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6616 - binary_accuracy: 0.8398\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5152 - binary_accuracy: 0.8438\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8711 - binary_accuracy: 0.8418\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8033 - binary_accuracy: 0.8633\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 999us/step - loss: 0.8524 - binary_accuracy: 0.8574\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 983us/step - loss: 0.6025 - binary_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9856 - binary_accuracy: 0.8438\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4336 - binary_accuracy: 0.8652\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6415 - binary_accuracy: 0.8984\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.7618 - binary_accuracy: 0.8789\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0204 - binary_accuracy: 0.8359\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8933 - binary_accuracy: 0.8711\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1509 - binary_accuracy: 0.8672\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1834 - binary_accuracy: 0.8496\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2937 - binary_accuracy: 0.8438\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4704 - binary_accuracy: 0.8477\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 998us/step - loss: 0.7435 - binary_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 1.0481 - binary_accuracy: 0.8535\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.7166 - binary_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 985us/step - loss: 0.5418 - binary_accuracy: 0.8340\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 973us/step - loss: 1.4926 - binary_accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 945us/step - loss: 0.4472 - binary_accuracy: 0.8809\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 943us/step - loss: 1.2619 - binary_accuracy: 0.8574\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 917us/step - loss: 1.7284 - binary_accuracy: 0.8379\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.8255 - binary_accuracy: 0.8574\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5566 - binary_accuracy: 0.8535\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 954us/step - loss: 1.1644 - binary_accuracy: 0.8594\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 1.4799 - binary_accuracy: 0.8574\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.8347 - binary_accuracy: 0.8672\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4814 - binary_accuracy: 0.8594\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4751 - binary_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 982us/step - loss: 0.8833 - binary_accuracy: 0.8496\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.2997 - binary_accuracy: 0.8457\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 989us/step - loss: 1.0010 - binary_accuracy: 0.8594\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2733 - binary_accuracy: 0.8789\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2986 - binary_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.1286 - binary_accuracy: 0.8457\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 972us/step - loss: 1.0281 - binary_accuracy: 0.8457\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3728 - binary_accuracy: 0.8516\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.2106 - binary_accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 969us/step - loss: 1.6838 - binary_accuracy: 0.8633\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 1.3118 - binary_accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9816 - binary_accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 1.6154 - binary_accuracy: 0.8555\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4422 - binary_accuracy: 0.8594\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 1.4904 - binary_accuracy: 0.8555\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.6120 - binary_accuracy: 0.8535\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 962us/step - loss: 1.7302 - binary_accuracy: 0.8574\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.2642 - binary_accuracy: 0.8457\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 948us/step - loss: 1.9361 - binary_accuracy: 0.8457\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.7217 - binary_accuracy: 0.8594\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 1.1703 - binary_accuracy: 0.8555\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.8791 - binary_accuracy: 0.8457\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 1.6134 - binary_accuracy: 0.8574\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9042 - binary_accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8082 - binary_accuracy: 0.8555\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0683 - binary_accuracy: 0.8281\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.1711 - binary_accuracy: 0.8867\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 967us/step - loss: 0.6932 - binary_accuracy: 0.8594\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 3.0548 - binary_accuracy: 0.8477\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 990us/step - loss: 1.1529 - binary_accuracy: 0.8398\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.9730 - binary_accuracy: 0.8516\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 2.5270 - binary_accuracy: 0.8594\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.8333 - binary_accuracy: 0.8770\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4951 - binary_accuracy: 0.8438\n",
      "6/6 [==============================] - 0s 801us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 961us/step - loss: 1.3683 - binary_accuracy: 0.5781\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.7218 - binary_accuracy: 0.6543\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6422 - binary_accuracy: 0.6543\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5947 - binary_accuracy: 0.6973\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.5951 - binary_accuracy: 0.7168\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5597 - binary_accuracy: 0.7227\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.5753 - binary_accuracy: 0.7480\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5824 - binary_accuracy: 0.7695\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 943us/step - loss: 0.6383 - binary_accuracy: 0.7246\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5485 - binary_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.6467 - binary_accuracy: 0.7812\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5896 - binary_accuracy: 0.7773\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5746 - binary_accuracy: 0.8105\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 946us/step - loss: 0.6800 - binary_accuracy: 0.7734\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6237 - binary_accuracy: 0.8086\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 931us/step - loss: 0.5612 - binary_accuracy: 0.8047\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7286 - binary_accuracy: 0.8203\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.6766 - binary_accuracy: 0.8223\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4429 - binary_accuracy: 0.8457\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6561 - binary_accuracy: 0.8379\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.1709 - binary_accuracy: 0.8164\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 943us/step - loss: 1.2032 - binary_accuracy: 0.8223\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5373 - binary_accuracy: 0.8262\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.8363 - binary_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.5162 - binary_accuracy: 0.8516\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.8956 - binary_accuracy: 0.8516\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.5468 - binary_accuracy: 0.8711\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.7336 - binary_accuracy: 0.8359\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.8332 - binary_accuracy: 0.8477\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6169 - binary_accuracy: 0.8672\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.9494 - binary_accuracy: 0.8496\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6500 - binary_accuracy: 0.8613\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 1.0219 - binary_accuracy: 0.8574\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5439 - binary_accuracy: 0.8516\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.9255 - binary_accuracy: 0.8398\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.0268 - binary_accuracy: 0.8418\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 945us/step - loss: 1.0515 - binary_accuracy: 0.8398\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4163 - binary_accuracy: 0.8594\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 924us/step - loss: 1.3667 - binary_accuracy: 0.8496\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.1873 - binary_accuracy: 0.8887\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 982us/step - loss: 0.6978 - binary_accuracy: 0.8301\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4766 - binary_accuracy: 0.8672\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 932us/step - loss: 0.7449 - binary_accuracy: 0.8535\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.0358 - binary_accuracy: 0.8613\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 971us/step - loss: 1.4584 - binary_accuracy: 0.8770\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6529 - binary_accuracy: 0.8789\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 930us/step - loss: 0.7767 - binary_accuracy: 0.8672\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7356 - binary_accuracy: 0.8672\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7633 - binary_accuracy: 0.8672\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5607 - binary_accuracy: 0.8574\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5717 - binary_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.4143 - binary_accuracy: 0.8457\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8980 - binary_accuracy: 0.8730\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4457 - binary_accuracy: 0.8496\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.0633 - binary_accuracy: 0.8613\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5226 - binary_accuracy: 0.8652\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.8406 - binary_accuracy: 0.8730\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.5852 - binary_accuracy: 0.8555\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.1610 - binary_accuracy: 0.8535\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.3643 - binary_accuracy: 0.8633\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9784 - binary_accuracy: 0.8789\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.8553 - binary_accuracy: 0.8672\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.4548 - binary_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.9757 - binary_accuracy: 0.8535\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.7237 - binary_accuracy: 0.8457\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.7159 - binary_accuracy: 0.8535\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.2472 - binary_accuracy: 0.8711\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.1389 - binary_accuracy: 0.8438\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5519 - binary_accuracy: 0.8711\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.2329 - binary_accuracy: 0.8613\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.7174 - binary_accuracy: 0.8652\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.8071 - binary_accuracy: 0.8535\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.6348 - binary_accuracy: 0.8555\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3958 - binary_accuracy: 0.8691\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 3.2309 - binary_accuracy: 0.8672\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.3580 - binary_accuracy: 0.8574\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 4.5934 - binary_accuracy: 0.8359\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.6720 - binary_accuracy: 0.8750\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.1702 - binary_accuracy: 0.8477\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8037 - binary_accuracy: 0.8711\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4890 - binary_accuracy: 0.8672\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 3.4250 - binary_accuracy: 0.8672\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1472 - binary_accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.3375 - binary_accuracy: 0.8730\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.5058 - binary_accuracy: 0.8438\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.4442 - binary_accuracy: 0.8496\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.7250 - binary_accuracy: 0.8555\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.4751 - binary_accuracy: 0.8594\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.5835 - binary_accuracy: 0.8730\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9789 - binary_accuracy: 0.8711\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.4148 - binary_accuracy: 0.8496\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.3069 - binary_accuracy: 0.8418\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.0879 - binary_accuracy: 0.8555\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6672 - binary_accuracy: 0.8691\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4638 - binary_accuracy: 0.8633\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4619 - binary_accuracy: 0.8770\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 3.8528 - binary_accuracy: 0.8555\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.3443 - binary_accuracy: 0.8535\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.3028 - binary_accuracy: 0.8594\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7552 - binary_accuracy: 0.8574\n",
      "6/6 [==============================] - 0s 999us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 980us/step - loss: 1.6281 - binary_accuracy: 0.5391\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6320 - binary_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6708 - binary_accuracy: 0.6172\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5776 - binary_accuracy: 0.6191\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6027 - binary_accuracy: 0.6484\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5555 - binary_accuracy: 0.6504\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5460 - binary_accuracy: 0.7344\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5651 - binary_accuracy: 0.7383\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5137 - binary_accuracy: 0.7344\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5454 - binary_accuracy: 0.7598\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4963 - binary_accuracy: 0.7773\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5095 - binary_accuracy: 0.7812\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5537 - binary_accuracy: 0.7773\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 999us/step - loss: 0.5077 - binary_accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5872 - binary_accuracy: 0.7949\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6024 - binary_accuracy: 0.7832\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5306 - binary_accuracy: 0.8027\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5453 - binary_accuracy: 0.8008\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4911 - binary_accuracy: 0.8086\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5240 - binary_accuracy: 0.8047\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4669 - binary_accuracy: 0.7988\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5105 - binary_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5030 - binary_accuracy: 0.8047\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4545 - binary_accuracy: 0.8340\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5515 - binary_accuracy: 0.7969\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4412 - binary_accuracy: 0.8242\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4805 - binary_accuracy: 0.8262\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4584 - binary_accuracy: 0.8340\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.4373 - binary_accuracy: 0.8242\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5149 - binary_accuracy: 0.8281\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4991 - binary_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4977 - binary_accuracy: 0.8320\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4901 - binary_accuracy: 0.8262\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3988 - binary_accuracy: 0.8535\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4501 - binary_accuracy: 0.8457\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4069 - binary_accuracy: 0.8496\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.4721 - binary_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4204 - binary_accuracy: 0.8516\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5249 - binary_accuracy: 0.8281\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4812 - binary_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5006 - binary_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4205 - binary_accuracy: 0.8340\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4267 - binary_accuracy: 0.8281\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4022 - binary_accuracy: 0.8555\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.3601 - binary_accuracy: 0.8770\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3931 - binary_accuracy: 0.8711\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4838 - binary_accuracy: 0.8281\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.4389 - binary_accuracy: 0.8438\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4692 - binary_accuracy: 0.8535\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4327 - binary_accuracy: 0.8574\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4421 - binary_accuracy: 0.8457\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.3912 - binary_accuracy: 0.8496\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4669 - binary_accuracy: 0.8418\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.4241 - binary_accuracy: 0.8672\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3918 - binary_accuracy: 0.8594\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4619 - binary_accuracy: 0.8418\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4616 - binary_accuracy: 0.8438\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.3933 - binary_accuracy: 0.8613\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.4615 - binary_accuracy: 0.8301\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5246 - binary_accuracy: 0.8535\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4745 - binary_accuracy: 0.8184\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3897 - binary_accuracy: 0.8555\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3992 - binary_accuracy: 0.8594\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4446 - binary_accuracy: 0.8496\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4395 - binary_accuracy: 0.8496\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4083 - binary_accuracy: 0.8652\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3615 - binary_accuracy: 0.8672\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4353 - binary_accuracy: 0.8496\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4450 - binary_accuracy: 0.8613\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3621 - binary_accuracy: 0.8848\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4565 - binary_accuracy: 0.8379\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4895 - binary_accuracy: 0.8574\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3578 - binary_accuracy: 0.8672\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3824 - binary_accuracy: 0.8730\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.4244 - binary_accuracy: 0.8652\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4587 - binary_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4564 - binary_accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4489 - binary_accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3764 - binary_accuracy: 0.8691\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4364 - binary_accuracy: 0.8555\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3630 - binary_accuracy: 0.8652\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4898 - binary_accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3781 - binary_accuracy: 0.8867\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4081 - binary_accuracy: 0.8672\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3996 - binary_accuracy: 0.8516\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4525 - binary_accuracy: 0.8691\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4357 - binary_accuracy: 0.8652\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5601 - binary_accuracy: 0.8691\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4405 - binary_accuracy: 0.8496\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.4505 - binary_accuracy: 0.8516\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3454 - binary_accuracy: 0.8789\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4381 - binary_accuracy: 0.8613\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4599 - binary_accuracy: 0.8340\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3808 - binary_accuracy: 0.8711\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3277 - binary_accuracy: 0.8750\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3363 - binary_accuracy: 0.8789\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.3845 - binary_accuracy: 0.8906\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.3487 - binary_accuracy: 0.8672\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.3362 - binary_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4454 - binary_accuracy: 0.8691\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 980us/step - loss: 1.1891 - binary_accuracy: 0.5176\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.6440 - binary_accuracy: 0.6152\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5906 - binary_accuracy: 0.6074\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5444 - binary_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5546 - binary_accuracy: 0.7402\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6336 - binary_accuracy: 0.7266\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5290 - binary_accuracy: 0.7188\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6151 - binary_accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6551 - binary_accuracy: 0.7695\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5996 - binary_accuracy: 0.7461\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5141 - binary_accuracy: 0.7363\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4735 - binary_accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6891 - binary_accuracy: 0.7637\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5122 - binary_accuracy: 0.7812\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5218 - binary_accuracy: 0.8066\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6799 - binary_accuracy: 0.7910\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.7320 - binary_accuracy: 0.7637\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5921 - binary_accuracy: 0.7930\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6598 - binary_accuracy: 0.7734\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4937 - binary_accuracy: 0.7910\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.5653 - binary_accuracy: 0.7695\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.5707 - binary_accuracy: 0.7949\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5530 - binary_accuracy: 0.8125\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6033 - binary_accuracy: 0.7949\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5481 - binary_accuracy: 0.8066\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5043 - binary_accuracy: 0.8086\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7760 - binary_accuracy: 0.8105\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6641 - binary_accuracy: 0.8184\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.4726 - binary_accuracy: 0.8242\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4608 - binary_accuracy: 0.8164\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6659 - binary_accuracy: 0.8203\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.9563 - binary_accuracy: 0.8301\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.9974 - binary_accuracy: 0.8184\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5660 - binary_accuracy: 0.8125\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7014 - binary_accuracy: 0.8203\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5384 - binary_accuracy: 0.7969\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.4625 - binary_accuracy: 0.8398\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4872 - binary_accuracy: 0.8320\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4792 - binary_accuracy: 0.8105\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4595 - binary_accuracy: 0.8398\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6140 - binary_accuracy: 0.8281\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4141 - binary_accuracy: 0.8301\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9022 - binary_accuracy: 0.8164\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7326 - binary_accuracy: 0.8027\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7692 - binary_accuracy: 0.8047\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5630 - binary_accuracy: 0.8477\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6144 - binary_accuracy: 0.8535\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.9783 - binary_accuracy: 0.8320\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6630 - binary_accuracy: 0.8438\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6434 - binary_accuracy: 0.8301\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.4617 - binary_accuracy: 0.8320\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0544 - binary_accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6956 - binary_accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.2463 - binary_accuracy: 0.8320\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5956 - binary_accuracy: 0.8438\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6376 - binary_accuracy: 0.8320\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5623 - binary_accuracy: 0.8398\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7090 - binary_accuracy: 0.8359\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.7623 - binary_accuracy: 0.8418\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6577 - binary_accuracy: 0.8223\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6885 - binary_accuracy: 0.8086\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.1851 - binary_accuracy: 0.8477\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6358 - binary_accuracy: 0.8535\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.9193 - binary_accuracy: 0.8203\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6140 - binary_accuracy: 0.8242\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.8583 - binary_accuracy: 0.8242\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.0484 - binary_accuracy: 0.8438\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.0443 - binary_accuracy: 0.8223\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.7588 - binary_accuracy: 0.8516\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.1950 - binary_accuracy: 0.8555\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.1415 - binary_accuracy: 0.8535\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.4400 - binary_accuracy: 0.8574\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6023 - binary_accuracy: 0.8555\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.3171 - binary_accuracy: 0.8262\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9957 - binary_accuracy: 0.8301\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 1.3041 - binary_accuracy: 0.8496\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.8402 - binary_accuracy: 0.8457\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5419 - binary_accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9845 - binary_accuracy: 0.8203\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.9400 - binary_accuracy: 0.8672\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6392 - binary_accuracy: 0.8477\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0078 - binary_accuracy: 0.8516\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0691 - binary_accuracy: 0.8555\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.1862 - binary_accuracy: 0.8613\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 952us/step - loss: 0.9590 - binary_accuracy: 0.8477\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.5630 - binary_accuracy: 0.8398\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.9485 - binary_accuracy: 0.8672\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 2.1530 - binary_accuracy: 0.8359\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.5096 - binary_accuracy: 0.8613\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.6412 - binary_accuracy: 0.8398\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.1149 - binary_accuracy: 0.8398\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 2.4540 - binary_accuracy: 0.8457\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 1.1385 - binary_accuracy: 0.8457\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.2686 - binary_accuracy: 0.8398\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.6092 - binary_accuracy: 0.8281\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 2.1631 - binary_accuracy: 0.8613\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.7017 - binary_accuracy: 0.8633\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.0130 - binary_accuracy: 0.8262\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 1.3111 - binary_accuracy: 0.8672\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.7546 - binary_accuracy: 0.8477\n",
      "6/6 [==============================] - 0s 1000us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 980us/step - loss: 0.8076 - binary_accuracy: 0.6211\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.6615 - binary_accuracy: 0.6484\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6169 - binary_accuracy: 0.6523\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.6684 - binary_accuracy: 0.6699\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5845 - binary_accuracy: 0.7227\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5972 - binary_accuracy: 0.6934\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6098 - binary_accuracy: 0.7168\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6174 - binary_accuracy: 0.7305\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5085 - binary_accuracy: 0.7617\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6618 - binary_accuracy: 0.7305\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5506 - binary_accuracy: 0.7383\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.5140 - binary_accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6513 - binary_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5345 - binary_accuracy: 0.8027\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5602 - binary_accuracy: 0.8145\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5259 - binary_accuracy: 0.8145\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.6604 - binary_accuracy: 0.7656\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6348 - binary_accuracy: 0.7812\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5022 - binary_accuracy: 0.8184\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6198 - binary_accuracy: 0.8066\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.6757 - binary_accuracy: 0.8320\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 922us/step - loss: 0.5147 - binary_accuracy: 0.7891\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5395 - binary_accuracy: 0.8262\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 941us/step - loss: 0.5475 - binary_accuracy: 0.8066\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4837 - binary_accuracy: 0.8164\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4556 - binary_accuracy: 0.8086\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5335 - binary_accuracy: 0.7988\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4816 - binary_accuracy: 0.7871\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4223 - binary_accuracy: 0.8379\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3872 - binary_accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6137 - binary_accuracy: 0.8164\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4354 - binary_accuracy: 0.8379\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4404 - binary_accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5837 - binary_accuracy: 0.8008\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4876 - binary_accuracy: 0.8535\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5068 - binary_accuracy: 0.8535\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4263 - binary_accuracy: 0.8457\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7241 - binary_accuracy: 0.8262\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7870 - binary_accuracy: 0.8203\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6599 - binary_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6519 - binary_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4394 - binary_accuracy: 0.8496\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6061 - binary_accuracy: 0.8574\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5625 - binary_accuracy: 0.8438\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6271 - binary_accuracy: 0.8301\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4666 - binary_accuracy: 0.8516\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4478 - binary_accuracy: 0.8613\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5419 - binary_accuracy: 0.8359\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5061 - binary_accuracy: 0.8438\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4256 - binary_accuracy: 0.8477\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8266 - binary_accuracy: 0.8477\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9683 - binary_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5107 - binary_accuracy: 0.8574\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6110 - binary_accuracy: 0.8633\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5285 - binary_accuracy: 0.8574\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6979 - binary_accuracy: 0.8262\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4897 - binary_accuracy: 0.8867\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0597 - binary_accuracy: 0.8848\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9631 - binary_accuracy: 0.8555\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7740 - binary_accuracy: 0.8672\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8952 - binary_accuracy: 0.8516\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0758 - binary_accuracy: 0.8652\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6530 - binary_accuracy: 0.8828\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0719 - binary_accuracy: 0.8770\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.3192 - binary_accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6729 - binary_accuracy: 0.8457\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5278 - binary_accuracy: 0.8926\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5688 - binary_accuracy: 0.8730\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8879 - binary_accuracy: 0.8652\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4937 - binary_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7099 - binary_accuracy: 0.8789\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9906 - binary_accuracy: 0.8730\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4350 - binary_accuracy: 0.8809\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4267 - binary_accuracy: 0.8730\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5879 - binary_accuracy: 0.8672\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4621 - binary_accuracy: 0.8516\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9991 - binary_accuracy: 0.8691\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5589 - binary_accuracy: 0.8789\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4925 - binary_accuracy: 0.8848\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7599 - binary_accuracy: 0.8633\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4155 - binary_accuracy: 0.8672\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9152 - binary_accuracy: 0.8887\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6296 - binary_accuracy: 0.8770\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4586 - binary_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7820 - binary_accuracy: 0.8809\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.0742 - binary_accuracy: 0.8809\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5796 - binary_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7797 - binary_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6533 - binary_accuracy: 0.8730\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5011 - binary_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0841 - binary_accuracy: 0.8887\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6260 - binary_accuracy: 0.8750\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6179 - binary_accuracy: 0.8711\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7143 - binary_accuracy: 0.8633\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7500 - binary_accuracy: 0.8887\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.1292 - binary_accuracy: 0.8613\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1436 - binary_accuracy: 0.8984\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5493 - binary_accuracy: 0.8848\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6932 - binary_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8442 - binary_accuracy: 0.8633\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 1.1567 - binary_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7506 - binary_accuracy: 0.6328\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5862 - binary_accuracy: 0.6855\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6095 - binary_accuracy: 0.6895\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5913 - binary_accuracy: 0.7617\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4966 - binary_accuracy: 0.7715\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6308 - binary_accuracy: 0.7695\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5116 - binary_accuracy: 0.8086\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5189 - binary_accuracy: 0.7832\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5524 - binary_accuracy: 0.8008\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5624 - binary_accuracy: 0.7852\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5566 - binary_accuracy: 0.7988\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6211 - binary_accuracy: 0.8262\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5630 - binary_accuracy: 0.8184\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5413 - binary_accuracy: 0.8223\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5085 - binary_accuracy: 0.8242\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4344 - binary_accuracy: 0.8418\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6955 - binary_accuracy: 0.8223\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4986 - binary_accuracy: 0.8535\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6485 - binary_accuracy: 0.8027\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6363 - binary_accuracy: 0.8262\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4620 - binary_accuracy: 0.8223\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4994 - binary_accuracy: 0.8359\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5350 - binary_accuracy: 0.8477\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6258 - binary_accuracy: 0.8652\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9427 - binary_accuracy: 0.8340\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.7896 - binary_accuracy: 0.8359\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4117 - binary_accuracy: 0.8516\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4167 - binary_accuracy: 0.8574\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5789 - binary_accuracy: 0.8633\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6181 - binary_accuracy: 0.8457\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8322 - binary_accuracy: 0.8457\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4550 - binary_accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5518 - binary_accuracy: 0.8613\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4272 - binary_accuracy: 0.8672\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0806 - binary_accuracy: 0.8633\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3508 - binary_accuracy: 0.8555\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4721 - binary_accuracy: 0.8535\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6883 - binary_accuracy: 0.8398\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3336 - binary_accuracy: 0.8809\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8304 - binary_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3638 - binary_accuracy: 0.8789\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4290 - binary_accuracy: 0.8672\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3620 - binary_accuracy: 0.8906\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8484 - binary_accuracy: 0.8770\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4693 - binary_accuracy: 0.8730\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4612 - binary_accuracy: 0.8672\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9262 - binary_accuracy: 0.8613\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5729 - binary_accuracy: 0.8809\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9803 - binary_accuracy: 0.8652\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1904 - binary_accuracy: 0.8496\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6880 - binary_accuracy: 0.8516\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8071 - binary_accuracy: 0.8789\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2826 - binary_accuracy: 0.8613\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5915 - binary_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6787 - binary_accuracy: 0.8613\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5703 - binary_accuracy: 0.8633\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4683 - binary_accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4415 - binary_accuracy: 0.8848\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6383 - binary_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4569 - binary_accuracy: 0.8809\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8656 - binary_accuracy: 0.8789\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7350 - binary_accuracy: 0.8809\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6312 - binary_accuracy: 0.8809\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7283 - binary_accuracy: 0.8750\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8068 - binary_accuracy: 0.8535\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1688 - binary_accuracy: 0.8652\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0332 - binary_accuracy: 0.8711\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5613 - binary_accuracy: 0.8848\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4784 - binary_accuracy: 0.8750\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8705 - binary_accuracy: 0.8789\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4540 - binary_accuracy: 0.8613\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8383 - binary_accuracy: 0.8828\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1151 - binary_accuracy: 0.8848\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9521 - binary_accuracy: 0.8848\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3781 - binary_accuracy: 0.8711\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1406 - binary_accuracy: 0.8730\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7970 - binary_accuracy: 0.8652\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7924 - binary_accuracy: 0.8711\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8458 - binary_accuracy: 0.8809\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2230 - binary_accuracy: 0.8730\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7390 - binary_accuracy: 0.8809\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1584 - binary_accuracy: 0.8887\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9028 - binary_accuracy: 0.8711\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6451 - binary_accuracy: 0.8809\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7081 - binary_accuracy: 0.8789\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7536 - binary_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7145 - binary_accuracy: 0.8809\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - binary_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6298 - binary_accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.6575 - binary_accuracy: 0.8555\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8955 - binary_accuracy: 0.8711\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6223 - binary_accuracy: 0.8574\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7997 - binary_accuracy: 0.8789\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2445 - binary_accuracy: 0.8652\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7964 - binary_accuracy: 0.8613\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2892 - binary_accuracy: 0.8730\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8548 - binary_accuracy: 0.8633\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8125 - binary_accuracy: 0.8848\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6896 - binary_accuracy: 0.8535\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 1.2323 - binary_accuracy: 0.5547\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7229 - binary_accuracy: 0.6953\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6830 - binary_accuracy: 0.6836\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6694 - binary_accuracy: 0.6816\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5587 - binary_accuracy: 0.7070\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6245 - binary_accuracy: 0.7129\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5458 - binary_accuracy: 0.7402\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6682 - binary_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5799 - binary_accuracy: 0.7480\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5943 - binary_accuracy: 0.7363\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6244 - binary_accuracy: 0.7559\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6185 - binary_accuracy: 0.7441\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5982 - binary_accuracy: 0.7324\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5963 - binary_accuracy: 0.7324\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5245 - binary_accuracy: 0.7969\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5150 - binary_accuracy: 0.7793\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5815 - binary_accuracy: 0.7383\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5666 - binary_accuracy: 0.7578\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5042 - binary_accuracy: 0.7656\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5400 - binary_accuracy: 0.7891\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5123 - binary_accuracy: 0.8047\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5726 - binary_accuracy: 0.7773\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4916 - binary_accuracy: 0.7734\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5222 - binary_accuracy: 0.7793\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5297 - binary_accuracy: 0.8223\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5154 - binary_accuracy: 0.7832\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5310 - binary_accuracy: 0.7930\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5473 - binary_accuracy: 0.8047\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5000 - binary_accuracy: 0.7949\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6494 - binary_accuracy: 0.7930\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4958 - binary_accuracy: 0.8125\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5561 - binary_accuracy: 0.8047\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4897 - binary_accuracy: 0.8301\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4518 - binary_accuracy: 0.8164\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6039 - binary_accuracy: 0.8105\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6574 - binary_accuracy: 0.8047\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5088 - binary_accuracy: 0.8320\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9754 - binary_accuracy: 0.8105\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5692 - binary_accuracy: 0.8398\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5246 - binary_accuracy: 0.8379\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5301 - binary_accuracy: 0.8242\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8203 - binary_accuracy: 0.8477\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4707 - binary_accuracy: 0.8574\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6069 - binary_accuracy: 0.8223\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8276 - binary_accuracy: 0.8379\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4488 - binary_accuracy: 0.8457\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6019 - binary_accuracy: 0.8613\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6108 - binary_accuracy: 0.8555\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4894 - binary_accuracy: 0.8555\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7128 - binary_accuracy: 0.8418\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6276 - binary_accuracy: 0.8555\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8480 - binary_accuracy: 0.8340\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7934 - binary_accuracy: 0.8613\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7579 - binary_accuracy: 0.8535\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8965 - binary_accuracy: 0.8398\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9014 - binary_accuracy: 0.8496\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7580 - binary_accuracy: 0.8535\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6462 - binary_accuracy: 0.8594\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1873 - binary_accuracy: 0.8613\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7834 - binary_accuracy: 0.8516\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6939 - binary_accuracy: 0.8613\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9553 - binary_accuracy: 0.8281\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6044 - binary_accuracy: 0.8574\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8330 - binary_accuracy: 0.8047\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6641 - binary_accuracy: 0.8359\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8991 - binary_accuracy: 0.8613\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4657 - binary_accuracy: 0.8574\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4149 - binary_accuracy: 0.8926\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6184 - binary_accuracy: 0.8594\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.8535\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7756 - binary_accuracy: 0.8672\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5074 - binary_accuracy: 0.8672\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1641 - binary_accuracy: 0.8672\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9266 - binary_accuracy: 0.8711\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9011 - binary_accuracy: 0.8828\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3911 - binary_accuracy: 0.8672\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3478 - binary_accuracy: 0.8789\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4273 - binary_accuracy: 0.8535\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1692 - binary_accuracy: 0.8691\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6707 - binary_accuracy: 0.8535\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9352 - binary_accuracy: 0.8535\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4183 - binary_accuracy: 0.8867\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2363 - binary_accuracy: 0.8555\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.8267 - binary_accuracy: 0.8594\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2964 - binary_accuracy: 0.8379\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3736 - binary_accuracy: 0.8281\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4045 - binary_accuracy: 0.8535\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9952 - binary_accuracy: 0.8613\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7263 - binary_accuracy: 0.8730\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7051 - binary_accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7016 - binary_accuracy: 0.8906\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1148 - binary_accuracy: 0.8672\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8536 - binary_accuracy: 0.8613\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5520 - binary_accuracy: 0.8730\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6022 - binary_accuracy: 0.8750\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4206 - binary_accuracy: 0.8457\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8321 - binary_accuracy: 0.8906\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3893 - binary_accuracy: 0.8711\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6942 - binary_accuracy: 0.8750\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9274 - binary_accuracy: 0.8711\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 922us/step - loss: 1.4021 - binary_accuracy: 0.6035\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.8157 - binary_accuracy: 0.6523\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6223 - binary_accuracy: 0.6719\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5741 - binary_accuracy: 0.6973\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5334 - binary_accuracy: 0.7148\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5630 - binary_accuracy: 0.7441\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4980 - binary_accuracy: 0.7832\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5848 - binary_accuracy: 0.7695\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6844 - binary_accuracy: 0.7637\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6251 - binary_accuracy: 0.7715\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6425 - binary_accuracy: 0.7871\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6394 - binary_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6077 - binary_accuracy: 0.8027\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8791 - binary_accuracy: 0.7773\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6911 - binary_accuracy: 0.7969\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6917 - binary_accuracy: 0.7871\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5678 - binary_accuracy: 0.8086\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5398 - binary_accuracy: 0.8105\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8021 - binary_accuracy: 0.8066\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7470 - binary_accuracy: 0.7949\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0515 - binary_accuracy: 0.8066\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6373 - binary_accuracy: 0.8340\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8475 - binary_accuracy: 0.8145\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6549 - binary_accuracy: 0.8047\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4760 - binary_accuracy: 0.8281\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8895 - binary_accuracy: 0.8281\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9784 - binary_accuracy: 0.8223\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5408 - binary_accuracy: 0.8203\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9258 - binary_accuracy: 0.8281\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4762 - binary_accuracy: 0.8594\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9542 - binary_accuracy: 0.8457\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9495 - binary_accuracy: 0.8457\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6581 - binary_accuracy: 0.8555\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0420 - binary_accuracy: 0.8613\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8666 - binary_accuracy: 0.8516\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5514 - binary_accuracy: 0.8672\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6871 - binary_accuracy: 0.8652\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5552 - binary_accuracy: 0.8496\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3808 - binary_accuracy: 0.8320\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8343 - binary_accuracy: 0.8398\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1982 - binary_accuracy: 0.8555\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4794 - binary_accuracy: 0.8691\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6500 - binary_accuracy: 0.8477\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8693 - binary_accuracy: 0.8516\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0680 - binary_accuracy: 0.8281\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6932 - binary_accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0438 - binary_accuracy: 0.8711\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6227 - binary_accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6551 - binary_accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0410 - binary_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4157 - binary_accuracy: 0.8613\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8868 - binary_accuracy: 0.8438\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9924 - binary_accuracy: 0.8828\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6081 - binary_accuracy: 0.8633\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.9363 - binary_accuracy: 0.8613\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 1.3298 - binary_accuracy: 0.8691\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1526 - binary_accuracy: 0.8672\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5257 - binary_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8862 - binary_accuracy: 0.8809\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1629 - binary_accuracy: 0.8574\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6895 - binary_accuracy: 0.8672\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8872 - binary_accuracy: 0.8574\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.1976 - binary_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2423 - binary_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1919 - binary_accuracy: 0.8691\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2674 - binary_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9514 - binary_accuracy: 0.8867\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4602 - binary_accuracy: 0.8496\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6058 - binary_accuracy: 0.8828\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3545 - binary_accuracy: 0.8496\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9656 - binary_accuracy: 0.8535\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1644 - binary_accuracy: 0.8809\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2629 - binary_accuracy: 0.8789\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.3297 - binary_accuracy: 0.8535\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9555 - binary_accuracy: 0.8906\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5544 - binary_accuracy: 0.8711\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7064 - binary_accuracy: 0.8633\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.8962 - binary_accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5589 - binary_accuracy: 0.8203\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4790 - binary_accuracy: 0.8711\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4083 - binary_accuracy: 0.8652\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.2932 - binary_accuracy: 0.8574\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3176 - binary_accuracy: 0.8633\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2461 - binary_accuracy: 0.8672\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9451 - binary_accuracy: 0.8730\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2279 - binary_accuracy: 0.8828\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.7115 - binary_accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.6955 - binary_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2834 - binary_accuracy: 0.8926\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1065 - binary_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.3828 - binary_accuracy: 0.8809\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2020 - binary_accuracy: 0.8867\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9079 - binary_accuracy: 0.8848\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.5063 - binary_accuracy: 0.8770\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5717 - binary_accuracy: 0.8828\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3184 - binary_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3077 - binary_accuracy: 0.8887\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5235 - binary_accuracy: 0.8906\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9269 - binary_accuracy: 0.8887\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1450 - binary_accuracy: 0.9062\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athil\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 1ms/step - loss: 1.2106 - binary_accuracy: 0.5692\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7311 - binary_accuracy: 0.6043\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.6427 - binary_accuracy: 0.6511\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6341 - binary_accuracy: 0.6862\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6068 - binary_accuracy: 0.7251\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 980us/step - loss: 0.5488 - binary_accuracy: 0.7388\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5416 - binary_accuracy: 0.7719\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.5467 - binary_accuracy: 0.7758\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 1000us/step - loss: 0.4953 - binary_accuracy: 0.7797\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6873 - binary_accuracy: 0.7953\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6421 - binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5163 - binary_accuracy: 0.7973\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6011 - binary_accuracy: 0.7700\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6306 - binary_accuracy: 0.7953\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4770 - binary_accuracy: 0.8187\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5029 - binary_accuracy: 0.8226\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7643 - binary_accuracy: 0.7973\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4559 - binary_accuracy: 0.8382\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6249 - binary_accuracy: 0.8207\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4244 - binary_accuracy: 0.8382\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9784 - binary_accuracy: 0.8226\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6902 - binary_accuracy: 0.8343\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4551 - binary_accuracy: 0.8441\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4949 - binary_accuracy: 0.8441\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6269 - binary_accuracy: 0.8168\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8180 - binary_accuracy: 0.8148\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7513 - binary_accuracy: 0.8519\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7025 - binary_accuracy: 0.8226\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6105 - binary_accuracy: 0.8168\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4278 - binary_accuracy: 0.8596\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5011 - binary_accuracy: 0.8480\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5549 - binary_accuracy: 0.8499\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7695 - binary_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4012 - binary_accuracy: 0.8441\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8253 - binary_accuracy: 0.8363\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5026 - binary_accuracy: 0.8168\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6832 - binary_accuracy: 0.8304\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7465 - binary_accuracy: 0.8168\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5239 - binary_accuracy: 0.8343\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6426 - binary_accuracy: 0.8596\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5321 - binary_accuracy: 0.8441\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7111 - binary_accuracy: 0.8538\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4641 - binary_accuracy: 0.8168\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5356 - binary_accuracy: 0.8363\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4960 - binary_accuracy: 0.8538\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4516 - binary_accuracy: 0.8596\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7412 - binary_accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5118 - binary_accuracy: 0.8616\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8139 - binary_accuracy: 0.8304\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4999 - binary_accuracy: 0.8382\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6086 - binary_accuracy: 0.8460\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9627 - binary_accuracy: 0.8343\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5778 - binary_accuracy: 0.8460\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6320 - binary_accuracy: 0.8421\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5406 - binary_accuracy: 0.8480\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6453 - binary_accuracy: 0.8577\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6586 - binary_accuracy: 0.8558\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6354 - binary_accuracy: 0.8304\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8690 - binary_accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4366 - binary_accuracy: 0.8441\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8499\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6797 - binary_accuracy: 0.8480\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4747 - binary_accuracy: 0.8460\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9580 - binary_accuracy: 0.8460\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5571 - binary_accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6221 - binary_accuracy: 0.8519\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2500 - binary_accuracy: 0.8499\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5468 - binary_accuracy: 0.8713\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8238 - binary_accuracy: 0.8460\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8581 - binary_accuracy: 0.8596\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5458 - binary_accuracy: 0.8616\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4474 - binary_accuracy: 0.8538\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4703 - binary_accuracy: 0.8635\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1667 - binary_accuracy: 0.8772\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3941 - binary_accuracy: 0.8772\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4450 - binary_accuracy: 0.8596\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3985 - binary_accuracy: 0.8558\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8368 - binary_accuracy: 0.8635\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4435 - binary_accuracy: 0.8538\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7592 - binary_accuracy: 0.8558\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6019 - binary_accuracy: 0.8616\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5926 - binary_accuracy: 0.8558\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5258 - binary_accuracy: 0.8694\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0789 - binary_accuracy: 0.8480\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5544 - binary_accuracy: 0.8674\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4188 - binary_accuracy: 0.8421\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3829 - binary_accuracy: 0.8655\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.9239 - binary_accuracy: 0.8460\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5567 - binary_accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1921 - binary_accuracy: 0.8596\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5285 - binary_accuracy: 0.8635\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2911 - binary_accuracy: 0.8596\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4759 - binary_accuracy: 0.8635\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2290 - binary_accuracy: 0.8616\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4076 - binary_accuracy: 0.8674\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1539 - binary_accuracy: 0.8499\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.5577 - binary_accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4990 - binary_accuracy: 0.8635\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4344 - binary_accuracy: 0.8596\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0178 - binary_accuracy: 0.8616\n",
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_score(estimator = classificador, X = previsores, y = classe, cv = 10, scoring = 'accuracy', error_score='raise')\n",
    "#resultados = cross_val_score(estimator = classificador, X = previsores, y = classe, cv = 10, scoring = ['accuracy', 'precision', 'recall', 'f1'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media dos resultados e desvio padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = resultados.mean()\n",
    "desvio = resultados.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
